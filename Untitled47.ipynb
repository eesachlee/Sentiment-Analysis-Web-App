{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0067f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence sentiment\n",
      "0  So there is no way for me to plug it in here i...  negative\n",
      "1                        Good case, Excellent value.  positive\n",
      "2                             Great for the jawbone.  positive\n",
      "3  Tied to charger for conversations lasting more...  negative\n",
      "4                                  The mic is great.  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Acer\\Desktop\\Sentiment Analysis Web App\\archive\\combined_sentiment_data.csv\")\n",
    "\n",
    "# Check the first few rows of the data to confirm it's loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ee70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the new dataset\n",
    "file_path = r\"C:\\Users\\Acer\\Desktop\\Sentiment Analysis Web App\\archive\\combined_sentiment_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values in text or sentiment columns (if any)\n",
    "df.dropna(subset=['sentence', 'sentiment'], inplace=True)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df['sentence']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc247a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
